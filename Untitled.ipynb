{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5d60bc-0498-4fc1-a25e-6336fde52a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3019a1-d7c0-4e35-8326-dc78e798c3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/04 20:39:26 WARN Utils: Your hostname, ParienteLAP, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/12/04 20:39:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/04 20:39:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Ejemplo\").master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3606291b-59a4-46e5-aa68-f670142deb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.255.255.254:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Ejemplo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d6bb8247e30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66531e5-8004-4746-9a46-8889c09762b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Alicia', 25), ('Bob', 40), (\"Charlie\",35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e49fba9-996a-4794-96c2-bf8678439e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Name', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b517b242-dba7-4326-84cb-77564234089c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.classic.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, columns)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3bca79c-9921-44ff-91b2-4238a4847315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f407b25-4da3-4982-916c-1e3b04f645ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'bigint')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee67606-a1d5-44ab-9f11-3022af75b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'Name: string, Age: int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb278ec7-5eb8-4878-a80f-7aa5f7ab1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44fdf857-4088-4c93-a3b1-d325d334d0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f442fd44-d93b-40a5-9d1f-b5055ccfe2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abebb9dc-5376-4745-8465-4d888e10456d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "| Alicia| 25|\n",
      "|    Bob| 40|\n",
      "|Charlie| 35|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e6496ff-4e2d-4022-82f7-6b904b33fc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Alicia', Age=25), Row(Name='Bob', Age=40)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbe9b7e-4dc7-4883-b0f3-f2e29c80ec0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Name='Alicia', Age=25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee2df83-2ea0-47cf-955d-0a0867f80cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Bob', Age=40), Row(Name='Charlie', Age=35)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6256e64-0bd5-4df9-adbe-18f3be30aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|summary|   Name|               Age|\n",
      "+-------+-------+------------------+\n",
      "|  count|      3|                 3|\n",
      "|   mean|   NULL|33.333333333333336|\n",
      "| stddev|   NULL| 7.637626158259733|\n",
      "|    min| Alicia|                25|\n",
      "|    max|Charlie|                40|\n",
      "+-------+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dab6e3f4-4906-4115-8463-d5b51b6c00d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff2a3ab-f727-44c0-baa1-f7f4a0c3866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "| Alicia| 25|\n",
      "|    Bob| 40|\n",
      "|Charlie| 35|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "811385c7-8abf-4379-8523-8082cd0c4c85",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df.Age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f4e36f0-58f9-40d4-8e93-e5577627172c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Age'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b372edc-c8ba-44c6-8e83-746562945168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1d377fb-b120-4f53-acc3-ce00edb812d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkAttributeError",
     "evalue": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `Bob` is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPySparkAttributeError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBob\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:971\u001b[39m, in \u001b[36mDataFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Column:\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkAttributeError(\n\u001b[32m    972\u001b[39m             errorClass=\u001b[33m\"\u001b[39m\u001b[33mATTRIBUTE_NOT_SUPPORTED\u001b[39m\u001b[33m\"\u001b[39m, messageParameters={\u001b[33m\"\u001b[39m\u001b[33mattr_name\u001b[39m\u001b[33m\"\u001b[39m: name}\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m     jc = \u001b[38;5;28mself\u001b[39m._jdf.apply(name)\n\u001b[32m    975\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[31mPySparkAttributeError\u001b[39m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `Bob` is not supported."
     ]
    }
   ],
   "source": [
    "df.Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "250b2fe6-ba69-49d1-bb44-d507796dfca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "| Alicia|\n",
      "|    Bob|\n",
      "|Charlie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b83b3901-e96f-458c-9a79-0ed6d6242108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Age|\n",
      "+---+\n",
      "| 25|\n",
      "| 40|\n",
      "| 35|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d73e4c9-885a-4fc3-8720-21255a6caaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|Age|   Name|\n",
      "+---+-------+\n",
      "| 25| Alicia|\n",
      "| 40|    Bob|\n",
      "| 35|Charlie|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Age', 'Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9883242f-0009-4244-8a76-d2be5fb1cc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "| Alicia| 25|\n",
      "|    Bob| 40|\n",
      "|Charlie| 35|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "341b580a-40dc-4dbc-9fd1-6f1f3badb852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               Age|\n",
      "+-------+------------------+\n",
      "|  count|                 3|\n",
      "|   mean|33.333333333333336|\n",
      "| stddev| 7.637626158259733|\n",
      "|    min|                25|\n",
      "|    max|                40|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Age).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "566e8d26-c140-43e8-99dc-f84e876c45ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|    Bob| 40|\n",
      "|Charlie| 35|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Age > 30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aff5b33d-8bac-4ced-a95b-e01c3f45860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|    Bob| 40|\n",
      "|Charlie| 35|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Age > 30').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a35a8a5-b59b-41fb-8ef1-834a689ad4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|    Bob| 40|\n",
      "|Charlie| 35|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df['Age'] > 30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b143a150-0098-4ee7-8a96-4b516ac00c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"Roberto\", 15), (\"Ana\", 6), \n",
    "                             (\"Roberto\", 10), (\"Ana\", 6), \n",
    "                             (\"Ana\", 15)], \n",
    "                            'name:string, age:int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdd1d5eb-b2ed-43d5-bf02-b626d0e7ace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   name|count|\n",
      "+-------+-----+\n",
      "|Roberto|    2|\n",
      "|    Ana|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.groupBy('name').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10c2726c-8a3f-43e0-a594-4e17837c0527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 15|    2|\n",
      "|  6|    2|\n",
      "| 10|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.groupBy('age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bc900a6-762a-42d2-beeb-c6362f064c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|   name|sum(age)|\n",
      "+-------+--------+\n",
      "|Roberto|      25|\n",
      "|    Ana|      27|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f15b709-9351-46fb-bc9e-2f4b9126dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+\n",
      "|   name|age|count|\n",
      "+-------+---+-----+\n",
      "|Roberto| 15|    1|\n",
      "|    Ana|  6|    2|\n",
      "|Roberto| 10|    1|\n",
      "|    Ana| 15|    1|\n",
      "+-------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(['name', 'age']).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a73ae1b6-3584-4964-b308-13fa72128079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"libro1\",\"Hola mundo!, Estamos \\ \n",
    "                            listos para el lio.\"),\n",
    "                            (\"libro2\",\"Titulos. \\n vamos gente, es hora de \\n irnos\"),\n",
    "                            (\"libro3\",\"Este es el último libro y es el más normal.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4308cd6-ad35-4679-88a2-a7be7fc9411e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    _1|                  _2|\n",
      "+------+--------------------+\n",
      "|libro1|Hola mundo!, Esta...|\n",
      "|libro2|Titulos. \\n vamos...|\n",
      "|libro3|Este es el último...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3256160-4deb-4a27-88a1-457293c40d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnombre\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43medad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "df.columns(\"nombre\", \"edad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0126b97c-da67-459e-b842-fa8d3b6539f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnombre, edad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "df.columns(\"nombre, edad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68fb9e30-7fe5-462c-aa7a-1ba6ba7005fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'columns' of 'DataFrame' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m =[\u001b[33m\"\u001b[39m\u001b[33mnombre\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medad\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mAttributeError\u001b[39m: property 'columns' of 'DataFrame' object has no setter"
     ]
    }
   ],
   "source": [
    "df.columns =[\"nombre\", \"edad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a442b78c-6f7d-4173-aeaf-7044f20b904c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[nombre: string, contenido: string]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumnsRenamed({'_1':'nombre', '_2':'contenido'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09b7db07-c70e-411c-a662-6c3096106b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    _1|                  _2|\n",
      "+------+--------------------+\n",
      "|libro1|Hola mundo!, Esta...|\n",
      "|libro2|Titulos. \\n vamos...|\n",
      "|libro3|Este es el último...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01d29736-0e3c-445c-a8e3-88620ee63cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnsRenamed({'_1':'nombre', '_2':'contenido'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75950726-4b24-4d76-a45a-e1cd8c3b94bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|nombre|           contenido|\n",
      "+------+--------------------+\n",
      "|libro1|Hola mundo!, Esta...|\n",
      "|libro2|Titulos. \\n vamos...|\n",
      "|libro3|Este es el último...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "447d6bca-f12d-47b7-ad61-fa9992a69aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3608a6fb-a00b-4bc9-99e1-02f7cfba292b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (477040284.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf_filtrado = df.withColumn('contenido', regexp_replace('contenido', '[^a-zA-Z0-9]', ''))\u001b[39m\n                                                                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "df_filtrado = df.withColumn('contenido', regexp_replace('contenido', '[^a-zA-Z0-9]',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e346c619-81a1-49b8-a2f5-bafc9c864539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df.withColumn('contenido', regexp_replace('contenido', '[^a-zA-Z0-9]',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3ab1661-18a7-46d5-8ecf-022edceedbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|nombre|           contenido|\n",
      "+------+--------------------+\n",
      "|libro1|HolamundoEstamosl...|\n",
      "|libro2|Titulosvamosgente...|\n",
      "|libro3|Esteeselltimolibr...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afedce54-bff8-401c-b885-38a6d7a19227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df.withColumn('contenido', regexp_replace('contenido', '[^a-zA-Z0-9-\\\\s]',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3684096c-f25d-4900-906e-396c7b894dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|nombre|           contenido|\n",
      "+------+--------------------+\n",
      "|libro1|Hola mundo Estamo...|\n",
      "|libro2|Titulos  vamos ge...|\n",
      "|libro3|Este es el ltimo ...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5203fa01-9925-44a7-9bf0-510522c9f2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|nombre|           contenido|\n",
      "+------+--------------------+\n",
      "|libro1|Hola mundo!, Esta...|\n",
      "|libro2|Titulos. \\n vamos...|\n",
      "|libro3|Este es el último...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55a9d075-2024-434b-85bc-ea2066b290a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df_filtrado.withColumn('contenido', lower(df_filtrado.contenido))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db8b6078-98cd-462a-a4d1-0ab320cc2045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|nombre|           contenido|\n",
      "+------+--------------------+\n",
      "|libro1|hola mundo estamo...|\n",
      "|libro2|titulos  vamos ge...|\n",
      "|libro3|este es el ltimo ...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b37cc31c-d012-403d-8243-4cb36241c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4385d095-3241-4306-871f-4f7a3224fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"contenido\",\n",
    "    outputCol=\"contenido\",\n",
    "    pattern=\"\\\\W+\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e455ee6a-9e28-4141-b419-1e360a8a5cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "[FIELD_NOT_FOUND] No such struct field `text` in `nombre`, `contenido`. SQLSTATE: 42704",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIllegalArgumentException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_filtrado = \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_filtrado\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/base.py:260\u001b[39m, in \u001b[36mTransformer.transform\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._transform(dataset)\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/util.py:212\u001b[39m, in \u001b[36mtry_remote_transform_relation.<locals>.wrapped\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/wrapper.py:429\u001b[39m, in \u001b[36mJavaTransformer._transform\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28mself\u001b[39m._transfer_params_to_java()\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_java_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    284\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mIllegalArgumentException\u001b[39m: [FIELD_NOT_FOUND] No such struct field `text` in `nombre`, `contenido`. SQLSTATE: 42704"
     ]
    }
   ],
   "source": [
    "df_filtrado = tokenizer.transform(df_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40354d11-67db-4857-990c-26664d22afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"contenido\",\n",
    "    outputCol=\"words\",\n",
    "    pattern=\"\\\\W+\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a2588e6-7f0e-4f1f-bcd3-e3a2946f6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = tokenizer.transform(df_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c03f507b-4eed-4e9f-b9d4-1f1f8e5fe922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|nombre|           contenido|               words|\n",
      "+------+--------------------+--------------------+\n",
      "|libro1|hola mundo estamo...|[hola, mundo, est...|\n",
      "|libro2|titulos  vamos ge...|[titulos, vamos, ...|\n",
      "|libro3|este es el ltimo ...|[este, es, el, lt...|\n",
      "+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cd9e4-b8ea-40e3-83a3-faeb8f6d1cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4bc5aa2-4ab0-409a-b2ba-c0159f64f56c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Output column contenido already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIllegalArgumentException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m tokenizer = RegexTokenizer(\n\u001b[32m      2\u001b[39m     inputCol=\u001b[33m\"\u001b[39m\u001b[33mcontenido\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     outputCol=\u001b[33m\"\u001b[39m\u001b[33mcontenido\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     pattern=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mW+\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_filtrado = \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_filtrado\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df_filtrado.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/base.py:260\u001b[39m, in \u001b[36mTransformer.transform\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._transform(dataset)\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/util.py:212\u001b[39m, in \u001b[36mtry_remote_transform_relation.<locals>.wrapped\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/wrapper.py:429\u001b[39m, in \u001b[36mJavaTransformer._transform\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28mself\u001b[39m._transfer_params_to_java()\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_java_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    284\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mIllegalArgumentException\u001b[39m: Output column contenido already exists."
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"contenido\",\n",
    "    outputCol=\"contenido\",\n",
    "    pattern=\"\\\\W+\"\n",
    ")\n",
    "df_filtrado = tokenizer.transform(df_filtrado)\n",
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dabd676c-5980-460a-a261-faa2637eb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df.withColumn('contenido', regexp_replace('contenido', '[^a-zA-Z0-9 ]',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2148beab-84cd-473a-86bb-d7e457e3d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df_filtrado.withColumn('contenido', lower(df_filtrado.contenido))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11417c92-3f3c-4f7b-b7da-17cb1ad35cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|nombre|           contenido|\n",
      "+------+--------------------+\n",
      "|libro1|hola mundo estamo...|\n",
      "|libro2|titulos  vamos ge...|\n",
      "|libro3|este es el ltimo ...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53efac84-bc02-4287-8578-e69c89952e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"contenido\",\n",
    "    outputCol=\"contenido\",\n",
    "    pattern=\"\\\\W+\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de7b1748-e8b2-4ec9-bc81-0f3797ab76ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Output column contenido already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIllegalArgumentException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_filtrado = \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_filtrado\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_filtrado.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/base.py:260\u001b[39m, in \u001b[36mTransformer.transform\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._transform(dataset)\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/util.py:212\u001b[39m, in \u001b[36mtry_remote_transform_relation.<locals>.wrapped\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/ml/wrapper.py:429\u001b[39m, in \u001b[36mJavaTransformer._transform\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28mself\u001b[39m._transfer_params_to_java()\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_java_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    284\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mIllegalArgumentException\u001b[39m: Output column contenido already exists."
     ]
    }
   ],
   "source": [
    "df_filtrado = tokenizer.transform(df_filtrado)\n",
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2f1dadc-8b53-4ee7-9267-40f663e1d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|nombre|           contenido|            palabras|\n",
      "+------+--------------------+--------------------+\n",
      "|libro1|hola mundo estamo...|[hola, mundo, est...|\n",
      "|libro2|titulos  vamos ge...|[titulos, vamos, ...|\n",
      "|libro3|este es el ltimo ...|[este, es, el, lt...|\n",
      "+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"contenido\",\n",
    "    outputCol=\"palabras\",\n",
    "    pattern=\"\\\\W+\"\n",
    ")\n",
    "df_filtrado = tokenizer.transform(df_filtrado)\n",
    "df_filtrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac6eeddb-3ded-4811-ba0d-f33ded3070bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(\n",
    "    inputCol=\"palabras\",\n",
    "    outputCol=\"filtered\"\n",
    ")\n",
    "df_filtrado = remover.transform(df_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "571e11ce-4aac-4d69-ac8c-2463a8967b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkAttributeError",
     "evalue": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `filtered` is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPySparkAttributeError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_filtrado.select(\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiltered\u001b[49m).show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyecto/venv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:971\u001b[39m, in \u001b[36mDataFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Column:\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkAttributeError(\n\u001b[32m    972\u001b[39m             errorClass=\u001b[33m\"\u001b[39m\u001b[33mATTRIBUTE_NOT_SUPPORTED\u001b[39m\u001b[33m\"\u001b[39m, messageParameters={\u001b[33m\"\u001b[39m\u001b[33mattr_name\u001b[39m\u001b[33m\"\u001b[39m: name}\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m     jc = \u001b[38;5;28mself\u001b[39m._jdf.apply(name)\n\u001b[32m    975\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[31mPySparkAttributeError\u001b[39m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `filtered` is not supported."
     ]
    }
   ],
   "source": [
    "df_filtrado.select(df.filtered).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "266f08d8-b283-4da2-96e1-f8aafbdd329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|nombre|            filtered|\n",
      "+------+--------------------+\n",
      "|libro1|[hola, mundo, est...|\n",
      "|libro2|[titulos, vamos, ...|\n",
      "|libro3|[este, es, el, lt...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrado.select(\"nombre\", \"filtered\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "863caad8-d288-4b54-bfd6-e0672969141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------+\n",
      "|id |filtered                                        |\n",
      "+---+------------------------------------------------+\n",
      "|1  |[want, start, learning, change, something, life]|\n",
      "|2  |[never, stop, learning]                         |\n",
      "+---+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, \"i want to start learning to change something in life\"),\n",
    "    (2, \"never stop learning\")\n",
    "], [\"id\", \"text\"])\n",
    "\n",
    "# 1. Tokenizar\n",
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"text\",\n",
    "    outputCol=\"words\",\n",
    "    pattern=\"\\\\W+\"   # divide por cualquier cosa que no sea letra\n",
    ")\n",
    "\n",
    "df_tok = tokenizer.transform(df)\n",
    "\n",
    "# 2. Remover stopwords\n",
    "remover = StopWordsRemover(\n",
    "    inputCol=\"words\",\n",
    "    outputCol=\"filtered\"\n",
    ")\n",
    "\n",
    "df_clean = remover.transform(df_tok)\n",
    "\n",
    "df_clean.select(\"id\", \"filtered\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56dae5-ed24-422d-8136-f61a22688775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62dee6d4-a92f-41b0-9bb3-e71350229147",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'false' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_filtrado.show(truncate=\u001b[43mfalse\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'false' is not defined"
     ]
    }
   ],
   "source": [
    "df_filtrado.show(truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed072c1a-f202-4c66-bd90-bd67ba0ec961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------------+---------------------------------------------------+---------------------------------------------------+\n",
      "|nombre|contenido                               |palabras                                           |filtered                                           |\n",
      "+------+----------------------------------------+---------------------------------------------------+---------------------------------------------------+\n",
      "|libro1|hola mundo estamos  listos para el lio  |[hola, mundo, estamos, listos, para, el, lio]      |[hola, mundo, estamos, listos, para, el, lio]      |\n",
      "|libro2|titulos  vamos gente es hora de  irnos  |[titulos, vamos, gente, es, hora, de, irnos]       |[titulos, vamos, gente, es, hora, de, irnos]       |\n",
      "|libro3|este es el ltimo libro y es el ms normal|[este, es, el, ltimo, libro, y, es, el, ms, normal]|[este, es, el, ltimo, libro, y, es, el, ms, normal]|\n",
      "+------+----------------------------------------+---------------------------------------------------+---------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrado.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37397140-cfe3-4bc7-8d2c-fca749b60c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b96342-5574-4ab4-bb65-9dbb068eb50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
